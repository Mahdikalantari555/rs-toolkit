{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with YOLO\n",
    "\n",
    "This notebook demonstrates how to perform object detection on remote sensing imagery using the YOLO (You Only Look Once) model with the `ultralytics` library in Python. YOLO is effective for detecting objects like buildings, vehicles, or other features in high-resolution imagery.\n",
    "\n",
    "## Prerequisites\n",
    "- Install required libraries: `rasterio`, `ultralytics`, `numpy`, `matplotlib`, `geopandas` (listed in `requirements.txt`).\n",
    "- A high-resolution GeoTIFF file (e.g., `sample.tif`) and a shapefile with bounding box annotations (e.g., `annotations.shp`). Replace file paths with your own data.\n",
    "- GPU recommended for faster inference.\n",
    "\n",
    "## Learning Objectives\n",
    "- Prepare raster data and annotations for YOLO training.\n",
    "- Fine-tune a YOLO model for object detection.\n",
    "- Predict and visualize detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Data for YOLO\n",
    "\n",
    "Convert the raster and shapefile annotations into YOLO-compatible format (image patches and text files with bounding box coordinates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "image_path = 'sample.tif'\n",
    "shapefile_path = 'annotations.shp'\n",
    "output_dir = 'yolo_dataset/'\n",
    "patch_size = 640  # YOLO expects square images\n",
    "\n",
    "# Create directories\n",
    "Path(output_dir).mkdir(exist_ok=True)\n",
    "Path(f'{output_dir}/images').mkdir(exist_ok=True)\n",
    "Path(f'{output_dir}/labels').mkdir(exist_ok=True)\n",
    "\n",
    "# Load raster and shapefile\n",
    "with rasterio.open(image_path) as src:\n",
    "    image = src.read().transpose(1, 2, 0)  # Shape: (height, width, bands)\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "    profile = src.profile\n",
    "\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "if gdf.crs != crs:\n",
    "    gdf = gdf.to_crs(crs)\n",
    "\n",
    "# Extract patches and annotations\n",
    "height, width = image.shape[:2]\n",
    "for i in range(0, height, patch_size):\n",
    "    for j in range(0, width, patch_size):\n",
    "        # Extract patch\n",
    "        patch = image[i:i+patch_size, j:j+patch_size]\n",
    "        if patch.shape[:2] != (patch_size, patch_size):\n",
    "            continue\n",
    "        \n",
    "        # Save patch as image\n",
    "        patch_name = f'patch_{i}_{j}.jpg'\n",
    "        plt.imsave(f'{output_dir}/images/{patch_name}', patch / patch.max() if patch.max() > 0 else patch)\n",
    "        \n",
    "        # Get patch bounds\n",
    "        patch_bounds = rasterio.windows.from_bounds(\n",
    "            *rasterio.transform.xy(transform, i, j, rows=[i, i+patch_size], cols=[j, j+patch_size]),\n",
    "            transform=transform\n",
    "        ).bounds\n",
    "        \n",
    "        # Filter annotations within patch bounds\n",
    "        patch_gdf = gdf[gdf.geometry.intersects(gpd.GeoSeries.from_bounds(patch_bounds).geometry[0])]\n",
    "        \n",
    "        # Convert to YOLO format (class x_center y_center width height)\n",
    "        with open(f'{output_dir}/labels/{patch_name.replace(\".jpg\", \".txt\")}', 'w') as f:\n",
    "            for _, row in patch_gdf.iterrows():\n",
    "                class_id = row['class']  # Assumes 'class' column\n",
    "                bounds = row.geometry.bounds\n",
    "                x_min, y_min, x_max, y_max = bounds\n",
    "                x_center = ((x_min + x_max) / 2 - patch_bounds[0]) / (patch_bounds[2] - patch_bounds[0])\n",
    "                y_center = (1 - ((y_min + y_max) / 2 - patch_bounds[1]) / (patch_bounds[3] - patch_bounds[1]))\n",
    "                width = (x_max - x_min) / (patch_bounds[2] - patch_bounds[0])\n",
    "                height = (y_max - y_min) / (patch_bounds[3] - patch_bounds[1])\n",
    "                f.write(f'{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n')\n",
    "\n",
    "print(f'Dataset prepared in: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure YOLO Dataset\n",
    "\n",
    "Create a YAML configuration file for the YOLO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset YAML file\n",
    "yaml_content = f\"\"\"\n",
    "train: {output_dir}/images\n",
    "val: {output_dir}/images\n",
    "nc: {gdf['class'].nunique()}  # Number of classes\n",
    "names: {list(gdf['class'].unique())}  # Class names\n",
    "\"\"\"\n",
    "\n",
    "with open(f'{output_dir}/dataset.yaml', 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print('Dataset YAML file created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train YOLO Model\n",
    "\n",
    "Fine-tune a pretrained YOLO model on the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO model\n",
    "model = YOLO('yolov8n.pt')  # Load pretrained YOLOv8 nano model\n",
    "\n",
    "# Train model\n",
    "model.train(\n",
    "    data=f'{output_dir}/dataset.yaml',\n",
    "    epochs=10,\n",
    "    imgsz=patch_size,\n",
    "    batch=8,\n",
    "    device=0 if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Predict and Visualize Detections\n",
    "\n",
    "Perform object detection on the raster and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model (adjust path to trained weights)\n",
    "model = YOLO('runs/detect/train/weights/best.pt')  # Update path after training\n",
    "\n",
    "# Initialize output array for visualization\n",
    "with rasterio.open(image_path) as src:\n",
    "    image = src.read().transpose(1, 2, 0)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "# Predict on patches\n",
    "results = []\n",
    "for i in range(0, height, patch_size):\n",
    "    for j in range(0, width, patch_size):\n",
    "        patch = image[i:i+patch_size, j:j+patch_size]\n",
    "        if patch.shape[:2] != (patch_size, patch_size):\n",
    "            continue\n",
    "        result = model.predict(patch, save=False)\n",
    "        results.append((result, i, j))\n",
    "\n",
    "# Visualize detections\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image / image.max() if image.max() > 0 else image)\n",
    "for result, i, j in results:\n",
    "    for box in result.boxes:\n",
    "        x_min, y_min, x_max, y_max = box.xyxy[0].cpu().numpy()\n",
    "        x_min, y_min, x_max, y_max = x_min + j, y_min + i, x_max + j, y_max + i\n",
    "        plt.gca().add_patch(plt.Rectangle((x_min, y_min), x_max-x_min, y_max-y_min, edgecolor='red', facecolor='none', lw=2))\n",
    "plt.title('YOLO Object Detection Results')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save Detection Results\n",
    "\n",
    "Save detected bounding boxes as a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrame for detections\n",
    "boxes = []\n",
    "for result, i, j in results:\n",
    "    for box in result.boxes:\n",
    "        x_min, y_min, x_max, y_max = box.xyxy[0].cpu().numpy()\n",
    "        x_min, y_min, x_max, y_max = x_min + j, y_min + i, x_max + j, y_max + i\n",
    "        x_min_geo, y_max_geo = rasterio.transform.xy(transform, y_min, x_min)\n",
    "        x_max_geo, y_min_geo = rasterio.transform.xy(transform, y_max, x_max)\n",
    "        boxes.append({\n",
    "            'geometry': gpd.GeoSeries.from_bounds((x_min_geo, y_min_geo, x_max_geo, y_max_geo)).geometry[0],\n",
    "            'class': int(box.cls.cpu().numpy())\n",
    "        })\n",
    "\n",
    "gdf_detections = gpd.GeoDataFrame(boxes, crs=crs)\n",
    "gdf_detections.to_file('yolo_detections.shp')\n",
    "\n",
    "print('Detections saved to: yolo_detections.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Replace `sample.tif` and `annotations.shp` with your own image and bounding box annotations.\n",
    "- Adjust patch size, number of epochs, or use a different YOLO model (e.g., `yolov8m.pt`).\n",
    "- Add evaluation metrics (e.g., mAP) for model performance.\n",
    "- This is the final notebook in the series. Review previous notebooks for further analysis or explore advanced topics like multi-scale object detection.\n",
    "\n",
    "## Notes\n",
    "- Ensure the shapefile contains bounding box geometries with a 'class' column.\n",
    "- YOLO requires images in RGB format; convert multi-band rasters if needed.\n",
    "- See `docs/installation.md` for troubleshooting library installation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}