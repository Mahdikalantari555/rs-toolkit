{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Land Cover Classification\n",
    "\n",
    "This notebook demonstrates how to apply transfer learning for land cover classification of remote sensing imagery using a pre-trained deep learning model (ResNet) with `torch` and `torchvision` in Python. Transfer learning leverages pre-trained models to improve performance on small datasets, making it ideal for remote sensing tasks with limited labeled data.\n",
    "\n",
    "## Prerequisites\n",
    "- Install required libraries: `torch`, `torchvision`, `rasterio`, `geopandas`, `numpy`, `matplotlib`, `scikit-learn` (listed in `requirements.txt`).\n",
    "- A preprocessed multi-band GeoTIFF (e.g., `fused_feature_stack.tif` from `25_multisensor_fusion.ipynb`).\n",
    "- A labeled vector dataset (e.g., `landcover_labels.shp`) with land cover classes.\n",
    "- Replace file paths with your own data.\n",
    "- GPU recommended for faster training.\n",
    "\n",
    "## Learning Objectives\n",
    "- Load and preprocess remote sensing imagery and labeled vector data.\n",
    "- Fine-tune a pre-trained ResNet model for land cover classification.\n",
    "- Evaluate model performance using accuracy and confusion matrix.\n",
    "- Visualize predicted land cover classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Raster and Labeled Data\n",
    "\n",
    "Load the preprocessed multi-band GeoTIFF and labeled vector data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "raster_path = 'remote_sensing_data/fused_feature_stack.tif'  # Replace with your GeoTIFF\n",
    "labels_path = 'landcover_labels.shp'                        # Replace with your labeled shapefile\n",
    "\n",
    "# Load raster\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(masked=True)  # Shape: (bands, height, width)\n",
    "    raster_profile = src.profile\n",
    "    raster_crs = src.crs\n",
    "\n",
    "# Load labeled vector data\n",
    "labels_gdf = gpd.read_file(labels_path)\n",
    "if labels_gdf.crs != raster_crs:\n",
    "    labels_gdf = labels_gdf.to_crs(raster_crs)\n",
    "\n",
    "# Extract class labels (assumes 'class' column)\n",
    "class_names = labels_gdf['class'].unique()\n",
    "class_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "labels_gdf['class_id'] = labels_gdf['class'].map(class_map)\n",
    "\n",
    "# Print basic information\n",
    "print(f'Raster shape: {raster_data.shape}')\n",
    "print(f'Raster CRS: {raster_crs}')\n",
    "print(f'Labels CRS: {labels_gdf.crs}')\n",
    "print(f'Classes: {class_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Custom Dataset\n",
    "\n",
    "Extract image patches and corresponding labels to create a dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset class\n",
    "class RemoteSensingDataset(Dataset):\n",
    "    def __init__(self, raster_data, labels_gdf, transform=None, patch_size=64):\n",
    "        self.raster_data = raster_data\n",
    "        self.labels_gdf = labels_gdf\n",
    "        self.transform = transform\n",
    "        self.patch_size = patch_size\n",
    "        self.patches = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Extract patches and labels\n",
    "        height, width = raster_data.shape[1], raster_data.shape[2]\n",
    "        for idx, row in labels_gdf.iterrows():\n",
    "            centroid = row.geometry.centroid\n",
    "            row_idx, col_idx = rasterio.transform.rowcol(raster_profile['transform'], centroid.x, centroid.y)\n",
    "            if (row_idx - patch_size//2 >= 0 and row_idx + patch_size//2 < height and\n",
    "                col_idx - patch_size//2 >= 0 and col_idx + patch_size//2 < width):\n",
    "                patch = raster_data[:, row_idx-patch_size//2:row_idx+patch_size//2,\n",
    "                                    col_idx-patch_size//2:col_idx+patch_size//2]\n",
    "                if not np.any(np.isnan(patch)):\n",
    "                    self.patches.append(patch)\n",
    "                    self.labels.append(row['class_id'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.patches[idx].astype(np.float32)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            patch = self.transform(patch)\n",
    "        return patch, label\n",
    "\n",
    "# Define data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5] * raster_data.shape[0], std=[0.2] * raster_data.shape[0])\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = RemoteSensingDataset(raster_data, labels_gdf, transform=transform, patch_size=64)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize and Fine-Tune ResNet Model\n",
    "\n",
    "Load a pre-trained ResNet model and modify it for the number of classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ResNet model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify input layer to match number of input bands\n",
    "num_bands = raster_data.shape[0]\n",
    "model.conv1 = nn.Conv2d(num_bands, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Modify output layer to match number of classes\n",
    "num_classes = len(class_names)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for patches, labels in train_loader:\n",
    "        patches, labels = patches.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(patches)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for patches, labels in val_loader:\n",
    "            patches, labels = patches.to(device), labels.to(device)\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), 'resnet_landcover.pth')\n",
    "print('Trained model saved to: resnet_landcover.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Model Performance\n",
    "\n",
    "Evaluate the model on the validation set and compute accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for patches, labels in val_loader:\n",
    "        patches, labels = patches.to(device), labels.to(device)\n",
    "        outputs = model(patches)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute accuracy and confusion matrix\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues')\n",
    "plt.colorbar(label='Count')\n",
    "plt.xticks(np.arange(num_classes), class_names, rotation=45)\n",
    "plt.yticks(np.arange(num_classes), class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict and Visualize Land Cover\n",
    "\n",
    "Apply the trained model to the entire raster to generate a land cover map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict land cover across the entire raster\n",
    "patch_size = 64\n",
    "height, width = raster_data.shape[1], raster_data.shape[2]\n",
    "pred_map = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, height - patch_size + 1, patch_size):\n",
    "        for j in range(0, width - patch_size + 1, patch_size):\n",
    "            patch = raster_data[:, i:i+patch_size, j:j+patch_size].astype(np.float32)\n",
    "            if not np.any(np.isnan(patch)):\n",
    "                patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                output = model(patch_tensor)\n",
    "                pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "                pred_map[i:i+patch_size, j:j+patch_size] = pred\n",
    "\n",
    "# Visualize predicted land cover\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(pred_map, cmap='tab10', interpolation='nearest')\n",
    "plt.colorbar(ticks=np.arange(num_classes), label='Class')\n",
    "plt.clim(-0.5, num_classes-0.5)\n",
    "plt.title('Predicted Land Cover Map')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()\n",
    "\n",
    "# Save predicted land cover as GeoTIFF\n",
    "pred_profile = raster_profile.copy()\n",
    "pred_profile.update({'count': 1, 'dtype': 'uint8', 'nodata': None})\n",
    "pred_output_path = 'remote_sensing_data/landcover_prediction.tif'\n",
    "with rasterio.open(pred_output_path, 'w', **pred_profile) as dst:\n",
    "    dst.write(pred_map, 1)\n",
    "\n",
    "print(f'Predicted land cover saved to: {pred_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Replace `fused_feature_stack.tif` and `landcover_labels.shp` with your own GeoTIFF and labeled data (e.g., from `25_multisensor_fusion.ipynb`).\n",
    "- Adjust `patch_size` or model architecture (e.g., ResNet50) based on your dataset and computational resources.\n",
    "- Explore other pre-trained models (e.g., EfficientNet) or fine-tuning strategies to improve performance.\n",
    "- Use the predicted land cover map in visualization notebooks like `23_kepler_gl_demo.ipynb` or `22_folium_visualization.ipynb`.\n",
    "- Proceed to advanced analysis like change detection (see `18_change_detection.ipynb`) using the predicted maps.\n",
    "\n",
    "## Notes\n",
    "- Ensure the labeled shapefile contains a 'class' column with land cover categories.\n",
    "- The number of input bands must match the raster data; adjust the model input layer if using different sensors.\n",
    "- Transfer learning assumes sufficient labeled data; consider data augmentation if the dataset is small.\n",
    "- See `docs/installation.md` for troubleshooting library installation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}