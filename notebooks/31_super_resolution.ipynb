{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-Resolution for Remote Sensing Imagery\n",
    "\n",
    "This notebook demonstrates how to enhance the spatial resolution of remote sensing imagery (e.g., Sentinel-2) using a deep learning-based Super-Resolution Convolutional Neural Network (SRCNN) with `torch` in Python. Super-resolution improves image detail, enabling applications like detailed land cover mapping or urban analysis.\n",
    "\n",
    "## Prerequisites\n",
    "- Install required libraries: `torch`, `rasterio`, `geopandas`, `numpy`, `matplotlib`, `scikit-image` (listed in `requirements.txt`).\n",
    "- A preprocessed multi-band Sentinel-2 GeoTIFF (e.g., from `21_download_data.ipynb` or `24_advanced_preprocessing.ipynb`).\n",
    "- A GeoJSON or shapefile defining the area of interest (AOI) (e.g., `aoi.geojson`).\n",
    "- Replace file paths with your own data.\n",
    "- GPU recommended for faster training.\n",
    "\n",
    "## Learning Objectives\n",
    "- Load and preprocess Sentinel-2 imagery for super-resolution.\n",
    "- Train an SRCNN model to enhance image resolution.\n",
    "- Evaluate the super-resolved imagery using metrics like PSNR and SSIM.\n",
    "- Visualize and save the enhanced imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.transform import resize\n",
    "from rasterio.mask import mask\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Sentinel-2 Data and AOI\n",
    "\n",
    "Load a preprocessed Sentinel-2 GeoTIFF and crop it to the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "raster_path = 'remote_sensing_data/sentinel_rgb.tif'  # Replace with your Sentinel-2 GeoTIFF\n",
    "aoi_path = 'aoi.geojson'                             # Replace with your AOI file\n",
    "\n",
    "# Load raster\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data, transform = mask(src, aoi_gdf.geometry, crop=True, nodata=np.nan)\n",
    "    raster_profile = src.profile\n",
    "    raster_crs = src.crs\n",
    "raster_profile.update({\n",
    "    'height': raster_data.shape[1],\n",
    "    'width': raster_data.shape[2],\n",
    "    'transform': transform,\n",
    "    'nodata': np.nan\n",
    "})\n",
    "\n",
    "# Load AOI\n",
    "aoi_gdf = gpd.read_file(aoi_path)\n",
    "if aoi_gdf.crs != raster_crs:\n",
    "    aoi_gdf = aoi_gdf.to_crs(raster_crs)\n",
    "\n",
    "# Print basic information\n",
    "print(f'Raster shape: {raster_data.shape}')\n",
    "print(f'Raster CRS: {raster_crs}')\n",
    "print(f'AOI CRS: {aoi_gdf.crs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Dataset for SRCNN\n",
    "\n",
    "Create low-resolution (LR) and high-resolution (HR) image pairs for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset class\n",
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, raster_data, scale_factor=2, patch_size=64):\n",
    "        self.raster_data = raster_data\n",
    "        self.scale_factor = scale_factor\n",
    "        self.patch_size = patch_size\n",
    "        self.hr_patches = []\n",
    "        self.lr_patches = []\n",
    "\n",
    "        # Extract HR and LR patches\n",
    "        height, width = raster_data.shape[1], raster_data.shape[2]\n",
    "        for i in range(0, height - patch_size + 1, patch_size//2):\n",
    "            for j in range(0, width - patch_size + 1, patch_size//2):\n",
    "                hr_patch = raster_data[:, i:i+patch_size, j:j+patch_size]\n",
    "                if not np.any(np.isnan(hr_patch)):\n",
    "                    lr_patch = resize(hr_patch.transpose(1, 2, 0), (patch_size//scale_factor, patch_size//scale_factor), anti_aliasing=True)\n",
    "                    lr_patch = resize(lr_patch, (patch_size, patch_size), anti_aliasing=False).transpose(2, 0, 1)\n",
    "                    self.hr_patches.append(hr_patch)\n",
    "                    self.lr_patches.append(lr_patch)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_patch = self.hr_patches[idx].astype(np.float32)\n",
    "        lr_patch = self.lr_patches[idx].astype(np.float32)\n",
    "        return torch.from_numpy(lr_patch), torch.from_numpy(hr_patch)\n",
    "\n",
    "# Normalize raster data\n",
    "norm_raster_data = raster_data / np.nanpercentile(raster_data, 98, axis=(1, 2), keepdims=True)\n",
    "norm_raster_data = np.clip(norm_raster_data, 0, 1)\n",
    "\n",
    "# Create dataset\n",
    "dataset = SuperResolutionDataset(norm_raster_data, scale_factor=2, patch_size=64)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define and Train SRCNN Model\n",
    "\n",
    "Set up a Super-Resolution Convolutional Neural Network (SRCNN) for enhancing image resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SRCNN model\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels, 64, kernel_size=9, padding=4)\n",
    "        self.layer2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)\n",
    "        self.layer3 = nn.Conv2d(32, in_channels, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = SRCNN(in_channels=raster_data.shape[0]).to(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "train_losses, val_losses = [], []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for lr_patches, hr_patches in train_loader:\n",
    "        lr_patches, hr_patches = lr_patches.to(device), hr_patches.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lr_patches)\n",
    "        loss = criterion(outputs, hr_patches)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for lr_patches, hr_patches in val_loader:\n",
    "            lr_patches, hr_patches = lr_patches.to(device), hr_patches.to(device)\n",
    "            outputs = model(lr_patches)\n",
    "            loss = criterion(outputs, hr_patches)\n",
    "            val_loss += loss.item()\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), 'srcnn_super_resolution.pth')\n",
    "print('Trained model saved to: srcnn_super_resolution.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Super-Resolved Imagery\n",
    "\n",
    "Apply the trained SRCNN model to enhance the resolution of the entire raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create low-resolution input\n",
    "scale_factor = 2\n",
    "lr_data = resize(norm_raster_data.transpose(1, 2, 0), (norm_raster_data.shape[1]//scale_factor, norm_raster_data.shape[2]//scale_factor), anti_aliasing=True)\n",
    "lr_data = resize(lr_data, (norm_raster_data.shape[1], norm_raster_data.shape[2]), anti_aliasing=False).transpose(2, 0, 1)\n",
    "\n",
    "# Predict super-resolved imagery\n",
    "patch_size = 64\n",
    "height, width = norm_raster_data.shape[1], norm_raster_data.shape[2]\n",
    "sr_data = np.zeros_like(norm_raster_data, dtype=np.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, height - patch_size + 1, patch_size//2):\n",
    "        for j in range(0, width - patch_size + 1, patch_size//2):\n",
    "            patch = lr_data[:, i:i+patch_size, j:j+patch_size]\n",
    "            if not np.any(np.isnan(patch)):\n",
    "                patch_tensor = torch.from_numpy(patch.astype(np.float32)).unsqueeze(0).to(device)\n",
    "                sr_patch = model(patch_tensor).cpu().numpy()[0]\n",
    "                sr_data[:, i:i+patch_size, j:j+patch_size] = sr_patch\n",
    "\n",
    "# Denormalize super-resolved data\n",
    "sr_data = sr_data * np.nanpercentile(raster_data, 98, axis=(1, 2), keepdims=True)\n",
    "\n",
    "# Save super-resolved imagery\n",
    "sr_profile = raster_profile.copy()\n",
    "sr_output_path = 'remote_sensing_data/super_resolved.tif'\n",
    "with rasterio.open(sr_output_path, 'w', **sr_profile) as dst:\n",
    "    dst.write(sr_data)\n",
    "\n",
    "print(f'Super-resolved imagery saved to: {sr_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate and Visualize Results\n",
    "\n",
    "Compare the super-resolved imagery with the original and compute quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PSNR and SSIM for a sample patch\n",
    "sample_patch = norm_raster_data[:, :patch_size, :patch_size]\n",
    "sr_patch = sr_data[:, :patch_size, :patch_size]\n",
    "psnr_value = psnr(sample_patch.transpose(1, 2, 0), sr_patch.transpose(1, 2, 0), data_range=1.0)\n",
    "ssim_value = ssim(sample_patch.transpose(1, 2, 0), sr_patch.transpose(1, 2, 0), multichannel=True, data_range=1.0)\n",
    "\n",
    "print(f'PSNR: {psnr_value:.2f} dB')\n",
    "print(f'SSIM: {ssim_value:.4f}')\n",
    "\n",
    "# Visualize original, low-resolution, and super-resolved RGB\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax1.imshow(norm_raster_data[:3].transpose(1, 2, 0))\n",
    "ax1.set_title('Original RGB')\n",
    "ax1.set_xlabel('Column')\n",
    "ax1.set_ylabel('Row')\n",
    "ax2.imshow(lr_data[:3].transpose(1, 2, 0))\n",
    "ax2.set_title('Low-Resolution RGB')\n",
    "ax2.set_xlabel('Column')\n",
    "ax2.set_ylabel('Row')\n",
    "ax3.imshow(sr_data[:3].transpose(1, 2, 0))\n",
    "ax3.set_title('Super-Resolved RGB')\n",
    "ax3.set_xlabel('Column')\n",
    "ax3.set_ylabel('Row')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize with AOI Overlay\n",
    "\n",
    "Overlay the AOI on the super-resolved imagery for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize super-resolved imagery with AOI\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(sr_data[:3].transpose(1, 2, 0))\n",
    "aoi_gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "plt.title('Super-Resolved Imagery with AOI Overlay')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Replace `sentinel_rgb.tif` with your own Sentinel-2 GeoTIFF (e.g., from `21_download_data.ipynb`).\n",
    "- Update `aoi.geojson` with your area of interest file.\n",
    "- Experiment with other super-resolution models (e.g., ESRGAN) or different scale factors.\n",
    "- Use the super-resolved imagery in downstream tasks like classification (see `12_classification_rf_svm.ipynb` or `27_transfer_learning.ipynb`) or segmentation (see `15_unet_segmentation.ipynb`).\n",
    "- Visualize results with `23_kepler_gl_demo.ipynb` or `26_time_series_animation.ipynb`.\n",
    "\n",
    "## Notes\n",
    "- Ensure input imagery is preprocessed to remove clouds (see `28_cloud_detection_deep_learning.ipynb`).\n",
    "- Adjust `patch_size` and `scale_factor` based on your dataset and computational resources.\n",
    "- Super-resolution performance depends on training data quality; consider using high-resolution reference imagery if available.\n",
    "- See `docs/installation.md` for troubleshooting library installation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}