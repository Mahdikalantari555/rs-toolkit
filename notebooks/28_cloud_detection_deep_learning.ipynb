{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Detection with Deep Learning\n",
    "\n",
    "This notebook demonstrates how to use a deep learning model (U-Net) for cloud detection in remote sensing imagery using `torch` and `segmentation_models_pytorch` in Python. Unlike traditional methods (e.g., `09_cloud_masking.ipynb`), this approach leverages a convolutional neural network to segment clouds in Sentinel-2 imagery, providing higher accuracy for complex scenes.\n",
    "\n",
    "## Prerequisites\n",
    "- Install required libraries: `torch`, `segmentation_models_pytorch`, `rasterio`, `geopandas`, `numpy`, `matplotlib`, `scikit-learn` (listed in `requirements.txt`).\n",
    "- A preprocessed multi-band Sentinel-2 GeoTIFF (e.g., from `21_download_data.ipynb` or `24_advanced_preprocessing.ipynb`).\n",
    "- A labeled dataset (e.g., `cloud_labels.shp`) with binary cloud/no-cloud annotations or a pre-generated cloud mask raster.\n",
    "- Replace file paths with your own data.\n",
    "- GPU recommended for faster training.\n",
    "\n",
    "## Learning Objectives\n",
    "- Load and preprocess Sentinel-2 imagery and cloud mask labels.\n",
    "- Train a U-Net model for cloud segmentation.\n",
    "- Evaluate model performance using Intersection over Union (IoU) and accuracy.\n",
    "- Generate and visualize cloud masks for new imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Imagery and Cloud Labels\n",
    "\n",
    "Load a Sentinel-2 GeoTIFF and corresponding cloud mask labels (raster or vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "raster_path = 'remote_sensing_data/sentinel_rgb.tif'  # Replace with your Sentinel-2 GeoTIFF\n",
    "label_path = 'cloud_labels.tif'                      # Replace with your cloud mask raster\n",
    "aoi_path = 'aoi.geojson'                             # Replace with your AOI file\n",
    "\n",
    "# Load raster\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(masked=True)  # Shape: (bands, height, width)\n",
    "    raster_profile = src.profile\n",
    "    raster_crs = src.crs\n",
    "\n",
    "# Load cloud mask (assumes binary: 1=cloud, 0=no-cloud)\n",
    "with rasterio.open(label_path) as src:\n",
    "    cloud_mask = src.read(1, masked=True)  # Shape: (height, width)\n",
    "    label_profile = src.profile\n",
    "\n",
    "# Load AOI and align CRS\n",
    "aoi_gdf = gpd.read_file(aoi_path)\n",
    "if aoi_gdf.crs != raster_crs:\n",
    "    aoi_gdf = aoi_gdf.to_crs(raster_crs)\n",
    "\n",
    "# Crop raster and labels to AOI\n",
    "with rasterio.open(raster_path) as src:\n",
    "    cropped_raster, cropped_transform = mask(src, aoi_gdf.geometry, crop=True, nodata=np.nan)\n",
    "with rasterio.open(label_path) as src:\n",
    "    cropped_labels, _ = mask(src, aoi_gdf.geometry, crop=True, nodata=np.nan)\n",
    "\n",
    "# Update profiles\n",
    "cropped_profile = raster_profile.copy()\n",
    "cropped_profile.update({\n",
    "    'height': cropped_raster.shape[1],\n",
    "    'width': cropped_raster.shape[2],\n",
    "    'transform': cropped_transform,\n",
    "    'nodata': np.nan\n",
    "})\n",
    "\n",
    "# Print basic information\n",
    "print(f'Cropped raster shape: {cropped_raster.shape}')\n",
    "print(f'Cropped labels shape: {cropped_labels.shape}')\n",
    "print(f'Raster CRS: {raster_crs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Custom Dataset\n",
    "\n",
    "Extract image patches and corresponding cloud mask patches for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset class\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, raster_data, cloud_mask, patch_size=256):\n",
    "        self.raster_data = raster_data\n",
    "        self.cloud_mask = cloud_mask\n",
    "        self.patch_size = patch_size\n",
    "        self.patches = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Extract patches\n",
    "        height, width = raster_data.shape[1], raster_data.shape[2]\n",
    "        for i in range(0, height - patch_size + 1, patch_size//2):\n",
    "            for j in range(0, width - patch_size + 1, patch_size//2):\n",
    "                patch = raster_data[:, i:i+patch_size, j:j+patch_size]\n",
    "                label = cloud_mask[i:i+patch_size, j:j+patch_size]\n",
    "                if not np.any(np.isnan(patch)) and not np.any(np.isnan(label)):\n",
    "                    self.patches.append(patch)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.patches[idx].astype(np.float32)\n",
    "        label = self.labels[idx].astype(np.int64)\n",
    "        patch = torch.from_numpy(patch)\n",
    "        label = torch.from_numpy(label)\n",
    "        return patch, label\n",
    "\n",
    "# Create dataset\n",
    "dataset = CloudDataset(cropped_raster, cropped_labels, patch_size=256)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize and Train U-Net Model\n",
    "\n",
    "Set up a U-Net model with a pre-trained backbone and train it for cloud segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize U-Net model\n",
    "model = smp.Unet(\n",
    "    encoder_name='resnet18',\n",
    "    encoder_weights='imagenet',\n",
    "    in_channels=cropped_raster.shape[0],  # Number of input bands\n",
    "    classes=2                            # Cloud (1) and No-Cloud (0)\n",
    ").to(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = smp.losses.DiceLoss(mode='binary')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for patches, labels in train_loader:\n",
    "        patches, labels = patches.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(patches)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for patches, labels in val_loader:\n",
    "            patches, labels = patches.to(device), labels.to(device)\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "            val_loss += loss.item()\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), 'unet_cloud_detection.pth')\n",
    "print('Trained model saved to: unet_cloud_detection.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Model Performance\n",
    "\n",
    "Evaluate the model on the validation set using IoU and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def iou_score(preds, labels):\n",
    "    preds = preds > 0.5  # Threshold logits\n",
    "    intersection = (preds & labels).sum()\n",
    "    union = (preds | labels).sum()\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "ious = []\n",
    "with torch.no_grad():\n",
    "    for patches, labels in val_loader:\n",
    "        patches, labels = patches.to(device), labels.to(device)\n",
    "        outputs = torch.sigmoid(model(patches))\n",
    "        preds = (outputs > 0.5).cpu().numpy().astype(np.uint8)\n",
    "        all_preds.extend(preds.flatten())\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "        ious.append(iou_score(preds, labels.cpu().numpy()))\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "mean_iou = np.mean(ious)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "print(f'Mean IoU: {mean_iou:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues')\n",
    "plt.colorbar(label='Count')\n",
    "plt.xticks([0, 1], ['No-Cloud', 'Cloud'])\n",
    "plt.yticks([0, 1], ['No-Cloud', 'Cloud'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict and Visualize Cloud Mask\n",
    "\n",
    "Apply the trained U-Net model to the entire raster to generate a cloud mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict cloud mask across the entire raster\n",
    "patch_size = 256\n",
    "height, width = cropped_raster.shape[1], cropped_raster.shape[2]\n",
    "cloud_mask_pred = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, height - patch_size + 1, patch_size//2):\n",
    "        for j in range(0, width - patch_size + 1, patch_size//2):\n",
    "            patch = cropped_raster[:, i:i+patch_size, j:j+patch_size].astype(np.float32)\n",
    "            if not np.any(np.isnan(patch)):\n",
    "                patch_tensor = torch.from_numpy(patch).unsqueeze(0).to(device)\n",
    "                output = torch.sigmoid(model(patch_tensor)).cpu().numpy()\n",
    "                pred = (output[0, 0] > 0.5).astype(np.uint8)\n",
    "                cloud_mask_pred[i:i+patch_size, j:j+patch_size] = pred\n",
    "\n",
    "# Visualize predicted cloud mask\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cloud_mask_pred, cmap='gray')\n",
    "plt.title('Predicted Cloud Mask')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()\n",
    "\n",
    "# Save predicted cloud mask as GeoTIFF\n",
    "pred_profile = cropped_profile.copy()\n",
    "pred_profile.update({'count': 1, 'dtype': 'uint8', 'nodata': None})\n",
    "pred_output_path = 'remote_sensing_data/cloud_mask_pred.tif'\n",
    "with rasterio.open(pred_output_path, 'w', **pred_profile) as dst:\n",
    "    dst.write(cloud_mask_pred, 1)\n",
    "\n",
    "print(f'Predicted cloud mask saved to: {pred_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize with AOI Overlay\n",
    "\n",
    "Overlay the AOI on the predicted cloud mask and original RGB for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RGB with predicted cloud mask and AOI\n",
    "cropped_rgb = cropped_raster[:3].transpose(1, 2, 0)\n",
    "cropped_rgb = cropped_rgb / np.nanpercentile(cropped_rgb, 98) if np.nanpercentile(cropped_rgb, 98) > 0 else cropped_rgb\n",
    "cropped_rgb = np.clip(cropped_rgb, 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cropped_rgb)\n",
    "ax.imshow(cloud_mask_pred, cmap='Reds', alpha=0.5)\n",
    "aoi_gdf.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2)\n",
    "plt.title('RGB Composite with Predicted Cloud Mask and AOI')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Replace `sentinel_rgb.tif` and `cloud_labels.tif` with your own GeoTIFF and cloud mask data (e.g., from `21_download_data.ipynb`).\n",
    "- Update `aoi.geojson` with your area of interest file.\n",
    "- Experiment with other backbones (e.g., ResNet50, EfficientNet) or loss functions (e.g., Focal Loss) to improve performance.\n",
    "- Use the predicted cloud mask in preprocessing pipelines (e.g., `24_advanced_preprocessing.ipynb`) or visualization notebooks (e.g., `23_kepler_gl_demo.ipynb`).\n",
    "- Explore multi-class cloud detection (e.g., cloud types) by adjusting the number of output classes.\n",
    "\n",
    "## Notes\n",
    "- Ensure the cloud mask labels are binary (0=no-cloud, 1=cloud) and align with the input raster.\n",
    "- Large datasets may require smaller patch sizes or batch sizes to manage memory.\n",
    "- Pre-trained backbones improve convergence; consider freezing encoder weights for faster training on small datasets.\n",
    "- See `docs/installation.md` for troubleshooting library installation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}