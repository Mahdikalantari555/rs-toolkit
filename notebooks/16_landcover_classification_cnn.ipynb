{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Cover Classification with CNN\n",
    "\n",
    "This notebook demonstrates how to perform land cover classification using a Convolutional Neural Network (CNN) with `torch` in Python. The CNN classifies image patches extracted from a multi-band raster, suitable for remote sensing tasks like land cover mapping.\n",
    "\n",
    "## Prerequisites\n",
    "- Install required libraries: `rasterio`, `geopandas`, `torch`, `numpy`, `matplotlib` (listed in `requirements.txt`).\n",
    "- A multi-band GeoTIFF file (e.g., `sample.tif`) and a shapefile with labeled data (e.g., `labels.shp`). Replace file paths with your own data.\n",
    "- GPU recommended for faster training.\n",
    "\n",
    "## Learning Objectives\n",
    "- Extract labeled patches from a raster for CNN training.\n",
    "- Train a CNN for land cover classification.\n",
    "- Predict and visualize classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rasterio.features import geometry_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Custom Dataset\n",
    "\n",
    "Define a custom dataset to extract image patches centered on labeled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterPatchDataset(Dataset):\n",
    "    def __init__(self, image_path, shapefile_path, patch_size=64):\n",
    "        self.image_path = image_path\n",
    "        self.shapefile_path = shapefile_path\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        # Load shapefile\n",
    "        gdf = gpd.read_file(shapefile_path)\n",
    "        \n",
    "        # Load raster\n",
    "        with rasterio.open(image_path) as src:\n",
    "            self.image = src.read().astype(np.float32)\n",
    "            self.transform = src.transform\n",
    "            self.crs = src.crs\n",
    "            self.profile = src.profile\n",
    "        \n",
    "        # Reproject shapefile to match raster CRS\n",
    "        if gdf.crs != self.crs:\n",
    "            gdf = gdf.to_crs(self.crs)\n",
    "        \n",
    "        # Extract point coordinates and labels (assumes points with 'class' column)\n",
    "        self.points = gdf.geometry.centroid\n",
    "        self.labels = gdf['class'].values\n",
    "        \n",
    "        # Normalize image\n",
    "        self.image = self.image / np.max(self.image, axis=(1, 2), keepdims=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.points)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get point coordinates\n",
    "        point = self.points.iloc[idx]\n",
    "        x, y = point.x, point.y\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        row, col = ~self.transform * (x, y)\n",
    "        row, col = int(row), int(col)\n",
    "        \n",
    "        # Extract patch\n",
    "        half_patch = self.patch_size // 2\n",
    "        patch = self.image[:, row-half_patch:row+half_patch, col-half_patch:col+half_patch]\n",
    "        \n",
    "        # Ensure patch is correct size\n",
    "        if patch.shape[1:] != (self.patch_size, self.patch_size):\n",
    "            patch = np.zeros((self.image.shape[0], self.patch_size, self.patch_size), dtype=np.float32)\n",
    "        \n",
    "        # Get label\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return torch.from_numpy(patch), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define CNN Model\n",
    "\n",
    "Create a simple CNN architecture for patch classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)  # Adjust based on patch_size=64\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Data and Prepare Dataloaders\n",
    "\n",
    "Load the dataset, split into training/validation sets, and create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "image_path = 'sample.tif'\n",
    "shapefile_path = 'labels.shp'\n",
    "\n",
    "# Create dataset\n",
    "dataset = RasterPatchDataset(image_path, shapefile_path, patch_size=64)\n",
    "\n",
    "# Split into training and validation\n",
    "train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Print dataset information\n",
    "print(f'Total samples: {len(dataset)}')\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize and Train CNN\n",
    "\n",
    "Initialize the CNN and train it on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "n_classes = len(np.unique(dataset.labels))\n",
    "n_channels = dataset.image.shape[0]\n",
    "model = SimpleCNN(in_channels=n_channels, n_classes=n_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Training Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict and Visualize Classification\n",
    "\n",
    "Predict classifications across the raster using a sliding window approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full raster for prediction\n",
    "with rasterio.open(image_path) as src:\n",
    "    full_image = src.read().astype(np.float32)\n",
    "    profile = src.profile\n",
    "full_image = full_image / np.max(full_image, axis=(1, 2), keepdims=True)\n",
    "\n",
    "# Initialize output array\n",
    "height, width = full_image.shape[1], full_image.shape[2]\n",
    "predictions = np.zeros((height, width), dtype=np.int64)\n",
    "\n",
    "# Predict in patches\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, height, 64):\n",
    "        for j in range(0, width, 64):\n",
    "            patch = full_image[:, i:i+64, j:j+64]\n",
    "            if patch.shape[1:] != (64, 64):\n",
    "                continue  # Skip incomplete patches\n",
    "            patch = torch.from_numpy(patch).unsqueeze(0).to(device)\n",
    "            output = model(patch)\n",
    "            pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "            predictions[i:i+64, j:j+64] = pred\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(predictions, cmap='tab10')\n",
    "plt.colorbar(label='Class')\n",
    "plt.title('CNN Land Cover Classification')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Classification Result\n",
    "\n",
    "Save the classification result as a single-band GeoTIFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update profile for single-band output\n",
    "output_profile = profile.copy()\n",
    "output_profile.update(count=1, dtype=rasterio.int64)\n",
    "\n",
    "# Save predictions\n",
    "with rasterio.open('cnn_classification.tif', 'w', **output_profile) as dst:\n",
    "    dst.write(predictions, 1)\n",
    "\n",
    "print('Classification result saved to: cnn_classification.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Replace `sample.tif` and `labels.shp` with your own image and labeled shapefile.\n",
    "- Adjust patch size, number of epochs, or CNN architecture (e.g., add more layers).\n",
    "- Add validation metrics (e.g., accuracy, F1-score) for evaluation.\n",
    "- Proceed to the next notebook (`17_time_series_analysis.ipynb`) for time series analysis.\n",
    "\n",
    "## Notes\n",
    "- Ensure the shapefile contains points with a 'class' column for labels.\n",
    "- Normalize input data to improve training stability.\n",
    "- See `docs/installation.md` for troubleshooting library installation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}