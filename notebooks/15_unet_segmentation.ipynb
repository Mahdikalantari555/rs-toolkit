{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation with U-Net\n",
    "\n",
    "This notebook demonstrates how to perform semantic segmentation on remote sensing imagery using a U-Net model with `torch` and `segmentation-models-pytorch` in Python. U-Net is ideal for pixel-wise classification tasks, such as land cover segmentation.\n",
    "\n",
    "## Prerequisites\n",
    "- Install required libraries: `rasterio`, `torch`, `segmentation-models-pytorch`, `numpy`, `matplotlib` (listed in `requirements.txt`).\n",
    "- A multi-band GeoTIFF file (e.g., `sample.tif`) and a labeled raster mask (e.g., `mask.tif`) for training. Replace file paths with your own data.\n",
    "- GPU recommended for faster training.\n",
    "\n",
    "## Learning Objectives\n",
    "- Prepare raster data for U-Net training.\n",
    "- Train a U-Net model for semantic segmentation.\n",
    "- Predict and visualize segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from segmentation_models_pytorch import Unet\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Custom Dataset\n",
    "\n",
    "Define a custom dataset to load image patches and corresponding mask patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterDataset(Dataset):\n",
    "    def __init__(self, image_path, mask_path, patch_size=256):\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        # Load image and mask\n",
    "        with rasterio.open(image_path) as src_img, rasterio.open(mask_path) as src_mask:\n",
    "            self.image = src_img.read().astype(np.float32)\n",
    "            self.mask = src_mask.read(1).astype(np.int64)\n",
    "            self.profile = src_img.profile\n",
    "        \n",
    "        # Normalize image\n",
    "        self.image = self.image / np.max(self.image, axis=(1, 2), keepdims=True)\n",
    "        \n",
    "        # Get dimensions\n",
    "        self.height, self.width = self.image.shape[1:]\n",
    "        self.n_patches_x = self.width // patch_size\n",
    "        self.n_patches_y = self.height // patch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_patches_x * self.n_patches_y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate patch coordinates\n",
    "        y = (idx // self.n_patches_x) * self.patch_size\n",
    "        x = (idx % self.n_patches_x) * self.patch_size\n",
    "        \n",
    "        # Extract patch\n",
    "        img_patch = self.image[:, y:y+self.patch_size, x:x+self.patch_size]\n",
    "        mask_patch = self.mask[y:y+self.patch_size, x:x+self.patch_size]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        img_patch = torch.from_numpy(img_patch)\n",
    "        mask_patch = torch.from_numpy(mask_patch)\n",
    "        \n",
    "        return img_patch, mask_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data and Prepare Dataloaders\n",
    "\n",
    "Load the image and mask rasters, split into training/validation sets, and create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "image_path = 'sample.tif'\n",
    "mask_path = 'mask.tif'\n",
    "\n",
    "# Create dataset\n",
    "dataset = RasterDataset(image_path, mask_path, patch_size=256)\n",
    "\n",
    "# Split into training and validation\n",
    "train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Print dataset information\n",
    "print(f'Total patches: {len(dataset)}')\n",
    "print(f'Training patches: {len(train_dataset)}')\n",
    "print(f'Validation patches: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize U-Net Model\n",
    "\n",
    "Set up a U-Net model with a specified backbone and number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "n_classes = len(np.unique(dataset.mask))  # Number of classes in mask\n",
    "n_channels = dataset.image.shape[0]  # Number of input bands\n",
    "\n",
    "# Initialize U-Net model\n",
    "model = Unet(\n",
    "    encoder_name='resnet18',  # Use ResNet18 backbone\n",
    "    encoder_weights='imagenet',\n",
    "    in_channels=n_channels,\n",
    "    classes=n_classes\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model\n",
    "\n",
    "Train the U-Net model for a specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Training Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict and Visualize Segmentation\n",
    "\n",
    "Predict segmentation on the entire raster and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full raster for prediction\n",
    "with rasterio.open(image_path) as src:\n",
    "    full_image = src.read().astype(np.float32)\n",
    "    profile = src.profile\n",
    "full_image = full_image / np.max(full_image, axis=(1, 2), keepdims=True)\n",
    "\n",
    "# Initialize output array\n",
    "height, width = full_image.shape[1], full_image.shape[2]\n",
    "predictions = np.zeros((height, width), dtype=np.int64)\n",
    "\n",
    "# Predict in patches\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, height, 256):\n",
    "        for j in range(0, width, 256):\n",
    "            patch = full_image[:, i:i+256, j:j+256]\n",
    "            if patch.shape[1:] != (256, 256):\n",
    "                continue  # Skip incomplete patches\n",
    "            patch = torch.from_numpy(patch).unsqueeze(0).to(device)\n",
    "            output = model(patch)\n",
    "            pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "            predictions[i:i+256, j:j+256] = pred\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(predictions, cmap='tab10')\n",
    "plt.colorbar(label='Class')\n",
    "plt.title('U-Net Segmentation Result')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Segmentation Result\n",
    "\n",
    "Save the segmentation result as a single-band GeoTIFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update profile for single-band output\n",
    "output_profile = profile.copy()\n",
    "output_profile.update(count=1, dtype=rasterio.int64)\n",
    "\n",
    "# Save predictions\n",
    "with rasterio.open('unet_segmentation.tif', 'w', **output_profile) as dst:\n",
    "    dst.write(predictions, 1)\n",
    "\n",
    "print('Segmentation result saved to: unet_segmentation.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Replace `sample.tif` and `mask.tif` with your own image and labeled mask.\n",
    "- Adjust patch size, number of epochs, or model architecture (e.g., `encoder_name`).\n",
    "- Add validation metrics (e.g., IoU, accuracy) for model evaluation.\n",
    "- Proceed to the next notebook (`16_landcover_classification_cnn.ipynb`) for CNN-based classification.\n",
    "\n",
    "## Notes\n",
    "- Ensure the mask raster has integer class labels starting from 0.\n",
    "- Normalize input data to improve training stability.\n",
    "- See `docs/installation.md` for troubleshooting library installation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}