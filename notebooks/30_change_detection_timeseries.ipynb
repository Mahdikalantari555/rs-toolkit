{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Change Detection for Remote Sensing\n",
    "\n",
    "This notebook demonstrates how to detect changes in a time series of remote sensing imagery (e.g., Sentinel-2) using Change Vector Analysis (CVA) and a deep learning-based Siamese network with `rasterio`, `geopandas`, `numpy`, `torch`, and `keplergl` in Python. This is useful for monitoring land cover changes, deforestation, or urban expansion over time.\n",
    "\n",
    "## Prerequisites\n",
    "- Install required libraries: `rasterio`, `geopandas`, `numpy`, `matplotlib`, `torch`, `keplergl`, `scikit-learn` (listed in `requirements.txt`).\n",
    "- A stack of preprocessed GeoTIFF files representing a time series (e.g., from `21_download_data.ipynb` or `24_advanced_preprocessing.ipynb`).\n",
    "- A GeoJSON or shapefile defining the area of interest (AOI) (e.g., `aoi.geojson`).\n",
    "- Replace file paths with your own data.\n",
    "- GPU recommended for faster training of the Siamese network.\n",
    "\n",
    "## Learning Objectives\n",
    "- Load and preprocess a time series of raster data.\n",
    "- Perform Change Vector Analysis (CVA) for statistical change detection.\n",
    "- Train a Siamese network for deep learning-based change detection.\n",
    "- Visualize change maps interactively using Kepler.gl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.warp import transform_bounds\n",
    "from rasterio.mask import mask\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keplergl import KeplerGl\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Time Series Rasters and AOI\n",
    "\n",
    "Load a series of preprocessed GeoTIFF files and the AOI vector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "raster_dir = 'remote_sensing_data/time_series/'  # Directory with time series GeoTIFFs\n",
    "aoi_path = 'aoi.geojson'                        # Replace with your AOI file\n",
    "raster_files = sorted(glob.glob(os.path.join(raster_dir, '*.tif')))  # Replace with your file pattern\n",
    "\n",
    "# Load rasters and extract dates\n",
    "raster_stack = []\n",
    "dates = []\n",
    "for file in raster_files:\n",
    "    with rasterio.open(file) as src:\n",
    "        raster_data, transform = mask(src, aoi_gdf.geometry, crop=True, nodata=np.nan)\n",
    "        raster_stack.append(raster_data)  # Shape: (bands, height, width)\n",
    "        profile = src.profile\n",
    "        raster_crs = src.crs\n",
    "    profile.update({\n",
    "        'height': raster_data.shape[1],\n",
    "        'width': raster_data.shape[2],\n",
    "        'transform': transform,\n",
    "        'nodata': np.nan\n",
    "    })\n",
    "    # Extract date from filename (assumes format like 'sentinel_2023_01_01.tif')\n",
    "    date_str = os.path.basename(file).split('_')[1]  # Adjust based on your naming convention\n",
    "    dates.append(datetime.strptime(date_str, '%Y_%m_%d'))\n",
    "\n",
    "# Convert to numpy array\n",
    "raster_stack = np.stack(raster_stack, axis=0)  # Shape: (time, bands, height, width)\n",
    "\n",
    "# Load AOI\n",
    "aoi_gdf = gpd.read_file(aoi_path)\n",
    "if aoi_gdf.crs != raster_crs:\n",
    "    aoi_gdf = aoi_gdf.to_crs(raster_crs)\n",
    "\n",
    "# Print basic information\n",
    "print(f'Time series shape: {raster_stack.shape}')\n",
    "print(f'Dates: {dates}')\n",
    "print(f'Raster CRS: {raster_crs}')\n",
    "print(f'AOI CRS: {aoi_gdf.crs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Change Vector Analysis (CVA)\n",
    "\n",
    "Perform CVA to detect changes between consecutive time steps using spectral bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select bands for CVA (e.g., Red and NIR for Sentinel-2)\n",
    "red_band_idx = 0  # Adjust based on your band order\n",
    "nir_band_idx = 3\n",
    "\n",
    "# Compute CVA magnitude between consecutive time steps\n",
    "cva_magnitude = []\n",
    "for t in range(1, len(raster_stack)):\n",
    "    t1_data = raster_stack[t-1, [red_band_idx, nir_band_idx]]\n",
    "    t2_data = raster_stack[t, [red_band_idx, nir_band_idx]]\n",
    "    delta = t2_data - t1_data\n",
    "    magnitude = np.sqrt(np.sum(delta ** 2, axis=0))\n",
    "    cva_magnitude.append(magnitude)\n",
    "\n",
    "# Convert to numpy array\n",
    "cva_magnitude = np.stack(cva_magnitude, axis=0)  # Shape: (time-1, height, width)\n",
    "\n",
    "# Visualize CVA magnitude for the first change\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cva_magnitude[0], cmap='hot', vmin=np.nanpercentile(cva_magnitude[0], 2), vmax=np.nanpercentile(cva_magnitude[0], 98))\n",
    "plt.colorbar(label='Change Magnitude')\n",
    "plt.title(f'CVA Magnitude ({dates[0].strftime(\"%Y-%m-%d\")} to {dates[1].strftime(\"%Y-%m-%d\")})')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()\n",
    "\n",
    "# Save CVA magnitude as GeoTIFF\n",
    "cva_profile = profile.copy()\n",
    "cva_profile.update({'count': 1, 'dtype': 'float32'})\n",
    "for t in range(len(cva_magnitude)):\n",
    "    cva_output_path = f'remote_sensing_data/cva_magnitude_t{t+1}.tif'\n",
    "    with rasterio.open(cva_output_path, 'w', **cva_profile) as dst:\n",
    "        dst.write(cva_magnitude[t], 1)\n",
    "    print(f'CVA magnitude saved to: {cva_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Dataset for Siamese Network\n",
    "\n",
    "Create a dataset of image patch pairs with change/no-change labels for training a Siamese network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset class for Siamese network\n",
    "class ChangeDetectionDataset(Dataset):\n",
    "    def __init__(self, raster_stack, change_labels, patch_size=64):\n",
    "        self.raster_stack = raster_stack\n",
    "        self.change_labels = change_labels  # Binary mask: 1=change, 0=no-change\n",
    "        self.patch_size = patch_size\n",
    "        self.pairs = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Extract patch pairs\n",
    "        height, width = raster_stack.shape[2], raster_stack.shape[3]\n",
    "        for t in range(1, len(raster_stack)):\n",
    "            for i in range(0, height - patch_size + 1, patch_size//2):\n",
    "                for j in range(0, width - patch_size + 1, patch_size//2):\n",
    "                    patch_t1 = raster_stack[t-1, :, i:i+patch_size, j:j+patch_size]\n",
    "                    patch_t2 = raster_stack[t, :, i:i+patch_size, j:j+patch_size]\n",
    "                    label = change_labels[t-1, i:i+patch_size, j:j+patch_size].mean() > 0.5\n",
    "                    if not np.any(np.isnan(patch_t1)) and not np.any(np.isnan(patch_t2)):\n",
    "                        self.pairs.append((patch_t1, patch_t2))\n",
    "                        self.labels.append(int(label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch_t1, patch_t2 = self.pairs[idx]\n",
    "        label = self.labels[idx]\n",
    "        patch_t1 = torch.from_numpy(patch_t1.astype(np.float32))\n",
    "        patch_t2 = torch.from_numpy(patch_t2.astype(np.float32))\n",
    "        return patch_t1, patch_t2, label\n",
    "\n",
    "# Generate synthetic change labels for demonstration (replace with actual labels)\n",
    "change_labels = (cva_magnitude > np.nanpercentile(cva_magnitude, 95, axis=(1, 2), keepdims=True)).astype(np.uint8)\n",
    "\n",
    "# Create dataset\n",
    "dataset = ChangeDetectionDataset(raster_stack, change_labels, patch_size=64)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define and Train Siamese Network\n",
    "\n",
    "Set up a Siamese network to learn differences between image pairs for change detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Siamese network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return torch.softmax(output1 - output2, dim=1)\n",
    "\n",
    "# Initialize model\n",
    "model = SiameseNetwork(in_channels=raster_stack.shape[1]).to(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for patch_t1, patch_t2, labels in train_loader:\n",
    "        patch_t1, patch_t2, labels = patch_t1.to(device), patch_t2.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(patch_t1, patch_t2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for patch_t1, patch_t2, labels in val_loader:\n",
    "            patch_t1, patch_t2, labels = patch_t1.to(device), patch_t2.to(device), labels.to(device)\n",
    "            outputs = model(patch_t1, patch_t2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), 'siamese_change_detection.pth')\n",
    "print('Trained model saved to: siamese_change_detection.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict and Visualize Change Map\n",
    "\n",
    "Apply the Siamese network to predict changes across the entire time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict changes for the first time step pair\n",
    "patch_size = 64\n",
    "height, width = raster_stack.shape[2], raster_stack.shape[3]\n",
    "change_map = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, height - patch_size + 1, patch_size//2):\n",
    "        for j in range(0, width - patch_size + 1, patch_size//2):\n",
    "            patch_t1 = raster_stack[0, :, i:i+patch_size, j:j+patch_size]\n",
    "            patch_t2 = raster_stack[1, :, i:i+patch_size, j:j+patch_size]\n",
    "            if not np.any(np.isnan(patch_t1)) and not np.any(np.isnan(patch_t2)):\n",
    "                patch_t1 = torch.from_numpy(patch_t1.astype(np.float32)).unsqueeze(0).to(device)\n",
    "                patch_t2 = torch.from_numpy(patch_t2.astype(np.float32)).unsqueeze(0).to(device)\n",
    "                output = model(patch_t1, patch_t2)\n",
    "                pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "                change_map[i:i+patch_size, j:j+patch_size] = pred\n",
    "\n",
    "# Visualize predicted change map\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(change_map, cmap='Reds')\n",
    "plt.title(f'Predicted Change Map ({dates[0].strftime(\"%Y-%m-%d\")} to {dates[1].strftime(\"%Y-%m-%d\")})')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.colorbar(ticks=[0, 1], label='Change (0=No, 1=Yes)')\n",
    "plt.show()\n",
    "\n",
    "# Save predicted change map as GeoTIFF\n",
    "change_profile = profile.copy()\n",
    "change_profile.update({'count': 1, 'dtype': 'uint8', 'nodata': None})\n",
    "change_output_path = 'remote_sensing_data/change_map.tif'\n",
    "with rasterio.open(change_output_path, 'w', **change_profile) as dst:\n",
    "    dst.write(change_map, 1)\n",
    "\n",
    "print(f'Predicted change map saved to: {change_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize with Kepler.gl\n",
    "\n",
    "Create an interactive visualization of the change map using Kepler.gl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save change map as PNG for Kepler.gl\n",
    "change_png_path = 'remote_sensing_data/change_map.png'\n",
    "imageio.imwrite(change_png_path, change_map * 255)\n",
    "\n",
    "# Initialize Kepler.gl map\n",
    "with rasterio.open(change_output_path) as src:\n",
    "    bounds = src.bounds\n",
    "bounds_latlon = transform_bounds(raster_crs, 'EPSG:4326', *bounds)\n",
    "\n",
    "map_config = {\n",
    "    'version': 'v1',\n",
    "    'config': {\n",
    "        'mapState': {\n",
    "            'latitude': (bounds_latlon[1] + bounds_latlon[3]) / 2,\n",
    "            'longitude': (bounds_latlon[0] + bounds_latlon[2]) / 2,\n",
    "            'zoom': 10\n",
    "        },\n",
    "        'mapStyle': {\n",
    "            'styleType': 'dark'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "m = KeplerGl(height=600, config=map_config)\n",
    "\n",
    "# Add change map as image layer\n",
    "m.add_data(\n",
    "    data={\n",
    "        'type': 'image',\n",
    "        'url': change_png_path,\n",
    "        'bounds': [bounds_latlon[0], bounds_latlon[1], bounds_latlon[2], bounds_latlon[3]]\n",
    "    },\n",
    "    name='Change Map'\n",
    ")\n",
    "\n",
    "# Add AOI as vector layer\n",
    "temp_geojson = 'temp_aoi.geojson'\n",
    "aoi_gdf.to_crs('EPSG:4326').to_file(temp_geojson, driver='GeoJSON')\n",
    "with open(temp_geojson, 'r') as f:\n",
    "    m.add_data(data=f.read(), name='AOI')\n",
    "\n",
    "# Configure visualization settings\n",
    "m.config['config']['visState'] = {\n",
    "    'layers': [\n",
    "        {\n",
    "            'type': 'grid',\n",
    "            'config': {\n",
    "                'dataId': 'Change Map',\n",
    "                'visualChannels': {'colorField': None, 'colorScale': 'quantile'}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'type': 'geojson',\n",
    "            'config': {\n",
    "                'dataId': 'AOI',\n",
    "                'visualChannels': {'colorField': None, 'color': [255, 0, 0], 'strokeColor': [255, 0, 0]}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Display map\n",
    "m\n",
    "\n",
    "# Save map to HTML\n",
    "output_map_path = 'change_map_interactive.html'\n",
    "m.save_to_html(file_name=output_map_path)\n",
    "print(f'Interactive change map saved to: {output_map_path}')\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove(temp_geojson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Replace `remote_sensing_data/time_series/*.tif` with your own time series GeoTIFFs (e.g., from `21_download_data.ipynb`).\n",
    "- Update `aoi.geojson` with your area of interest file.\n",
    "- Replace synthetic change labels with ground-truth data for more accurate Siamese network training.\n",
    "- Experiment with other change detection methods (e.g., PCA-based or deep learning with U-Net) for comparison.\n",
    "- Use the change map in visualization notebooks like `23_kepler_gl_demo.ipynb` or `26_time_series_animation.ipynb`.\n",
    "\n",
    "## Notes\n",
    "- Ensure all rasters in the time series have the same CRS, resolution, and dimensions (see `24_advanced_preprocessing.ipynb`).\n",
    "- CVA is sensitive to band selection; adjust indices (e.g., Red, NIR) based on your data.\n",
    "- Siamese network performance depends on labeled data quality; consider data augmentation for small datasets.\n",
    "- See `docs/installation.md` for troubleshooting library installation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}